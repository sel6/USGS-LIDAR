{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07987b71-d485-4772-9d17-9faf328c01ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib3\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pdal\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, Point, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8d2270-2c57-4b23-a0eb-b4e656716c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINX, MINY, MAXX, MAXY = [-93.759055, 41.925015, -93.766155, 41.935015]\n",
    "polygon = Polygon(((MINX, MINY), (MINX, MAXY), (MAXX, MAXY), (MAXX, MINY), (MINX, MINY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd8eb06a-d010-49f0-afd8-52447ef05d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UsgsLidar:\n",
    "    \n",
    "    def __init__(self, path = \"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/\", pipeline_json_path: str=\"../pipeline.json\") -> None:\n",
    "            \n",
    "        self.path = path\n",
    "        self.txt = self.read_txt(\"../data/filenames.txt\")\n",
    "        self.a = self.read_json(\"../pipeline.json\")\n",
    "        self.metadata = self.read_csv(\"../data/metadata.csv\")\n",
    "    \n",
    "    def read_json(self, json_path):\n",
    "        try:\n",
    "            with open(json_path) as js:\n",
    "                json_obj = json.load(js)\n",
    "            return json_obj\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print('File not found.')\n",
    "        \n",
    "    def fetch_polygon_boundaries(self, polygon: Polygon):\n",
    "        polygon_df = gpd.GeoDataFrame([polygon], columns=['geometry'])\n",
    "\n",
    "        polygon_df.set_crs(epsg=4326, inplace=True)\n",
    "        polygon_df['geometry'] = polygon_df['geometry'].to_crs(epsg=3857)\n",
    "        minx, miny, maxx, maxy = polygon_df['geometry'][0].bounds\n",
    "\n",
    "        polygon_input = 'POLYGON(('\n",
    "        xcords, ycords = polygon_df['geometry'][0].exterior.coords.xy\n",
    "        for x, y in zip(list(xcords), list(ycords)):\n",
    "            polygon_input += f'{x} {y}, '\n",
    "        polygon_input = polygon_input[:-2]\n",
    "        polygon_input += '))'\n",
    "\n",
    "        return f\"({[minx, maxx]},{[miny,maxy]})\", polygon_input\n",
    "    \n",
    "    def read_csv(self, csv_path, missing_values=[\"n/a\", \"na\", \"undefined\"]):\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path, na_values=missing_values)\n",
    "            return df\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print('File not found.')\n",
    "            \n",
    "    def fetch_pipeline (self, region: str, polygon: Polygon):\n",
    "        url = f\"{self.path}{region}/ept.json\"\n",
    "        boundary, poly = self.fetch_polygon_boundaries(polygon)\n",
    "        \n",
    "        self.a['pipeline'][0]['filename']= f\"{self.path}{region}/ept.json\"\n",
    "        self.a['pipeline'][0]['polygon'] = poly\n",
    "        self.a['pipeline'][0]['bounds'] = boundary\n",
    "        pipeline = pdal.Pipeline(json.dumps(self.a))\n",
    "        \n",
    "        return pipeline\n",
    "    \n",
    "    def execute_pipeline(self, polygon: Polygon, epsg=4326, region: str = \"IA_FullState\"):\n",
    "        \n",
    "        pipeline = self.fetch_pipeline(region, polygon)\n",
    "\n",
    "        try:\n",
    "            pipeline.execute()\n",
    "            return pipeline\n",
    "        except RuntimeError as e:\n",
    "            print('Pipeline execution failed')\n",
    "            print(e)\n",
    "    \n",
    "    \n",
    "    def create_gpd_df(self, epsg, pipe):\n",
    "        try:\n",
    "            cloud = []\n",
    "            elevations =[]\n",
    "            geometry=[]\n",
    "            for row in pipe.arrays[0]:\n",
    "                lst = row.tolist()[-3:]\n",
    "                cloud.append(lst)\n",
    "                elevations.append(lst[2])\n",
    "                point = Point(lst[0], lst[1])\n",
    "                geometry.append(point)\n",
    "            gpd_df = gpd.GeoDataFrame(columns=[\"elevation\", \"geometry\"])\n",
    "            gpd_df['elevation'] = elevations\n",
    "            gpd_df['geometry'] = geometry\n",
    "            gpd_df = gpd_df.set_geometry(\"geometry\")\n",
    "            gpd_df.set_crs(epsg = epsg, inplace=True)\n",
    "            return gpd_df\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "    def fetch_region_data(self, polygon: Polygon, epsg=4326):\n",
    "        pipeline = self.execute_pipeline(polygon, epsg)\n",
    "        return self.create_gpd_df(epsg, pipeline)\n",
    "    \n",
    "    def read_txt(self, txt_path) -> list:\n",
    "        try:\n",
    "            with open(txt_path, \"r\") as f:\n",
    "                text_file = f.read().splitlines()\n",
    "            \n",
    "            return text_file\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    def fetch_name_and_year(self, location: str) -> tuple:\n",
    "        \n",
    "        location = location.replace('/', '')\n",
    "        regex = '20[0-9][0-9]+'\n",
    "        match = re.search(regex, location)\n",
    "        if(match):\n",
    "          return (location[:match.start() - 1], location[match.start():match.end()])\n",
    "        else:\n",
    "          return (location, None)\n",
    "    \n",
    "   \n",
    "    def fetch_metadata(self):\n",
    "    \n",
    "        metadata = pd.DataFrame(columns=['filename', 'region',\n",
    "                          'year', 'xmin', 'xmax', 'ymin', 'ymax', 'points'])\n",
    "\n",
    "        index = 0\n",
    "        for lists in self.txt:\n",
    "          r = urllib3.PoolManager().request('GET', self.path + lists + \"ept.json\")\n",
    "          if r.status == 200:\n",
    "            j = json.loads(r.data)\n",
    "            region, year = self.fetch_name_and_year(lists)\n",
    "\n",
    "            metadata = metadata.append({\n",
    "                'filename': lists.replace('/', ''),\n",
    "                'region': region,\n",
    "                'year': year,\n",
    "                'xmin': j['bounds'][0],\n",
    "                'xmax': j['bounds'][3],\n",
    "                'ymin': j['bounds'][1],\n",
    "                'ymax': j['bounds'][4],\n",
    "                'points': j['points']}, ignore_index=True)\n",
    "\n",
    "            metadata.to_csv(\"../data/metadata.csv\")\n",
    "        \n",
    "        return(metadata)\n",
    "    \n",
    "    \n",
    "    def fetch_regions(self, polygon: Polygon, epsg=4326) -> list:\n",
    "    \n",
    "        polygon_df = gpd.GeoDataFrame([polygon], columns=['geometry'])\n",
    "\n",
    "        polygon_df.set_crs(epsg, inplace=True)\n",
    "        polygon_df['geometry'] = polygon_df['geometry'].to_crs(epsg=3857)\n",
    "        minx, miny, maxx, maxy = polygon_df['geometry'][0].bounds\n",
    "\n",
    "        cond_xmin = self.metadata.xmin <= minx\n",
    "        cond_xmax = self.metadata.xmax >= maxx\n",
    "        cond_ymin = self.metadata.ymin <= miny\n",
    "        cond_ymax = self.metadata.ymax >= maxy\n",
    "\n",
    "\n",
    "        df = self.metadata[cond_xmin & cond_xmax & cond_ymin & cond_ymax]\n",
    "        sort_df = df.sort_values(by=['year'])\n",
    "        regions = sort_df['filename'].to_list()\n",
    "        if(len(df)==0):\n",
    "            print(\"polygon is not located\")\n",
    "        \n",
    "        return regions   \n",
    "    \n",
    "    def fetch_data(self, polygon: Polygon, region=\"IA_FullState\") -> dict:\n",
    "        regions = self.fetch_regions(polygon)\n",
    "\n",
    "        region_dicto = {}\n",
    "        for i in regions:\n",
    "            if i==region:\n",
    "                year = (self.metadata[self.metadata.filename == i].year.values[0])\n",
    "                year = str(year)\n",
    "                \n",
    "                if(year==\"nan\"):\n",
    "                    year = \"Year: not_specified\"\n",
    "                \n",
    "                region_df = self.fetch_region_data(polygon)\n",
    "            \n",
    "                if region_df.empty == False:\n",
    "                    region_dicto[year] = region_df\n",
    "\n",
    "        return(region_dicto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715e21b4-e769-41c4-8908-5f33b5136733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLYGON((-10437210.259858532 5149753.664381643, -10437210.259858532 5151249.971344454, -10438000.628243161 5151249.971344454, -10438000.628243161 5149753.664381643, -10437210.259858532 5149753.664381643))\n"
     ]
    }
   ],
   "source": [
    "US = UsgsLidar()\n",
    "shape, poly = US.fetch_polygon_boundaries(polygon)\n",
    "print(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad3c397-2c1b-438d-aa60-6ff6c822af23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NE_Rainwater-2_2009',\n",
       " 'SD_James_River_NRCS_J_2010',\n",
       " 'SD_McCook_County_2012',\n",
       " 'SD_Spink_County_2012',\n",
       " 'USGS_LPC_NE_Hat_White_Cherry_UTM14_2016_LAS_2019',\n",
       " 'USGS_LPC_FL_Lower_Choctawhatchee_2017_LAS_2019',\n",
       " 'USGS_LPC_NE_NRCS_OrthoLidar_B2_2017_LAS_2019',\n",
       " 'IA_FullState']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US.fetch_regions(polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c04e66e-15e2-4f90-9771-d6a5df6cab95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Year: not_specified':         elevation                    geometry\n",
       " 0          307.78  POINT (-93.75913 41.93289)\n",
       " 1          307.79  POINT (-93.75912 41.93289)\n",
       " 2          307.69  POINT (-93.75911 41.93289)\n",
       " 3          307.64  POINT (-93.75908 41.93289)\n",
       " 4          307.66  POINT (-93.75906 41.93289)\n",
       " ...           ...                         ...\n",
       " 913969     326.90  POINT (-93.76560 41.93487)\n",
       " 913970     327.32  POINT (-93.76575 41.93487)\n",
       " 913971     328.34  POINT (-93.76539 41.93498)\n",
       " 913972     315.14  POINT (-93.76131 41.92578)\n",
       " 913973     318.21  POINT (-93.76133 41.93051)\n",
       " \n",
       " [913974 rows x 2 columns]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US.fetch_data(polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85106596-1535-4196-ae42-ea2ee9b5e939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320.62</td>\n",
       "      <td>POINT (-93.76411 41.93052)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320.63</td>\n",
       "      <td>POINT (-93.76410 41.93052)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320.63</td>\n",
       "      <td>POINT (-93.76411 41.93052)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>320.56</td>\n",
       "      <td>POINT (-93.76420 41.93052)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320.59</td>\n",
       "      <td>POINT (-93.76419 41.93052)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913969</th>\n",
       "      <td>308.19</td>\n",
       "      <td>POINT (-93.76052 41.93466)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913970</th>\n",
       "      <td>309.04</td>\n",
       "      <td>POINT (-93.76211 41.93465)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913971</th>\n",
       "      <td>314.48</td>\n",
       "      <td>POINT (-93.76371 41.93466)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913972</th>\n",
       "      <td>315.14</td>\n",
       "      <td>POINT (-93.76131 41.92578)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913973</th>\n",
       "      <td>318.21</td>\n",
       "      <td>POINT (-93.76133 41.93051)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>913974 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        elevation                    geometry\n",
       "0          320.62  POINT (-93.76411 41.93052)\n",
       "1          320.63  POINT (-93.76410 41.93052)\n",
       "2          320.63  POINT (-93.76411 41.93052)\n",
       "3          320.56  POINT (-93.76420 41.93052)\n",
       "4          320.59  POINT (-93.76419 41.93052)\n",
       "...           ...                         ...\n",
       "913969     308.19  POINT (-93.76052 41.93466)\n",
       "913970     309.04  POINT (-93.76211 41.93465)\n",
       "913971     314.48  POINT (-93.76371 41.93466)\n",
       "913972     315.14  POINT (-93.76131 41.92578)\n",
       "913973     318.21  POINT (-93.76133 41.93051)\n",
       "\n",
       "[913974 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US.fetch_region_data(polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a84a731-79bf-4163-bb21-3f0ef2f90891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(self, polygon: Polygon, region=\"IA_FullState\") -> dict:\n",
    "        regions = self.fetch_regions(polygon)\n",
    "\n",
    "        region_dicto = {}\n",
    "        for i in regions:\n",
    "            if i==region:\n",
    "                year = (self.metadata[self.metadata.filename == i].year.values[0])\n",
    "                year = str(year)\n",
    "                \n",
    "                if(year==\"nan\"):\n",
    "                    year = \"Year: not_specified\"\n",
    "                \n",
    "                region_df = self.fetch_region_data(polygon)\n",
    "            \n",
    "                if region_df.empty == False:\n",
    "                    region_dicto[year] = region_df\n",
    "\n",
    "        return(region_dicto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
